import json
import os
import sys
import io
from datetime import datetime
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass
import re
import firebase_admin
from firebase_admin import credentials, firestore
import numpy as np
from collections import defaultdict

# UTF-8 ì¸ì½”ë”© ì„¤ì •
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')

# Firebase ì´ˆê¸°í™”
try:
    service_account_path = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 'firebase-service-account-key.json')
    if not os.path.exists(service_account_path):
        service_account_path = 'firebase-service-account-key.json'
    
    cred = credentials.Certificate(service_account_path)
    firebase_admin.initialize_app(cred)
except ValueError:
    pass

db = firestore.client()

@dataclass
class ImprovementResult:
    """ê°œì„  ê²°ê³¼ ë°ì´í„°"""
    user_message: str
    original_response: str
    improved_response: str
    original_score: float
    improved_score: float
    improvement_rate: float
    applied: bool
    reason: str
    
@dataclass
class ValidationMetrics:
    """ê²€ì¦ ë©”íŠ¸ë¦­"""
    relevance_score: float  # ê´€ë ¨ì„± ì ìˆ˜ (0-100)
    naturalness_score: float  # ìì—°ìŠ¤ëŸ¬ì›€ ì ìˆ˜ (0-100)
    context_consistency: float  # ë¬¸ë§¥ ì¼ê´€ì„± (0-100)
    overall_score: float  # ì „ì²´ ì ìˆ˜ (0-100)

class ChatImprovementValidator:
    """ëŒ€í™” ê°œì„  ê²€ì¦ ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.improvement_patterns = {
            'question_mark_fix': {
                'pattern': r'[ê°€-í£]+[ë‚˜ìš”ê¹Œìš”][\.ã€‚]?$',
                'improvement': self._add_question_mark,
                'weight': 0.2
            },
            'expression_softening': {
                'pattern': r'(ë‚˜ìš”|ìŠµë‹ˆê¹Œ|ê¹Œìš”)\?',
                'improvement': self._soften_expression,
                'weight': 0.3
            },
            'empathy_enhancement': {
                'pattern': r'(ê·¸ëŸ° ê°ì •|ê·¸ëŸ° ê¸°ë¶„|ê·¸ëŸ° ë§ˆìŒ) (ì´í•´í•´ìš”|ì•Œì•„ìš”)',
                'improvement': self._enhance_empathy,
                'weight': 0.4
            },
            'direct_answer': {
                'pattern': r'(ë­í•´|ë­í•˜ê³ |ë­ í•˜ê³ )',
                'improvement': self._ensure_direct_answer,
                'weight': 0.5
            },
            'spoiler_handling': {
                'pattern': r'ìŠ¤í¬.*ë§í•´ë„',
                'improvement': self._handle_spoiler,
                'weight': 0.4
            },
            'context_understanding': {
                'pattern': r'ì§ì ‘ (ë³´|ë´)',
                'improvement': self._understand_context,
                'weight': 0.4
            }
        }
        
    def validate_improvement(self, user_message: str, original_response: str, 
                           improved_response: str, context: List[Dict] = None) -> ImprovementResult:
        """ê°œì„  ì „í›„ ì‘ë‹µì„ ë¹„êµí•˜ì—¬ ê²€ì¦"""
        
        # ì›ë³¸ê³¼ ê°œì„ ë³¸ì´ ë™ì¼í•œ ê²½ìš°
        if original_response == improved_response:
            return ImprovementResult(
                user_message=user_message,
                original_response=original_response,
                improved_response=improved_response,
                original_score=50.0,
                improved_score=50.0,
                improvement_rate=0.0,
                applied=False,
                reason="ê°œì„ ì‚¬í•­ ì—†ìŒ"
            )
        
        # ì ìˆ˜ ê³„ì‚°
        original_metrics = self._calculate_metrics(user_message, original_response, context)
        improved_metrics = self._calculate_metrics(user_message, improved_response, context)
        
        # ê°œì„ ìœ¨ ê³„ì‚°
        improvement_rate = ((improved_metrics.overall_score - original_metrics.overall_score) 
                           / original_metrics.overall_score * 100)
        
        # ê°œì„  ì ìš© ì—¬ë¶€ ê²°ì • (10% ì´ìƒ ê°œì„ ì‹œ ì ìš©)
        should_apply = improvement_rate >= 10.0
        
        reason = self._generate_reason(original_metrics, improved_metrics, improvement_rate)
        
        return ImprovementResult(
            user_message=user_message,
            original_response=original_response,
            improved_response=improved_response,
            original_score=original_metrics.overall_score,
            improved_score=improved_metrics.overall_score,
            improvement_rate=improvement_rate,
            applied=should_apply,
            reason=reason
        )
    
    def _calculate_metrics(self, user_message: str, response: str, 
                          context: List[Dict] = None) -> ValidationMetrics:
        """ì‘ë‹µì˜ í’ˆì§ˆ ë©”íŠ¸ë¦­ ê³„ì‚°"""
        
        # 1. ê´€ë ¨ì„± ì ìˆ˜ (40%)
        relevance = self._calculate_relevance(user_message, response)
        
        # 2. ìì—°ìŠ¤ëŸ¬ì›€ ì ìˆ˜ (30%)
        naturalness = self._calculate_naturalness(response, user_message)
        
        # 3. ë¬¸ë§¥ ì¼ê´€ì„± (30%)
        consistency = self._calculate_consistency(response, context) if context else 70.0
        
        # ì „ì²´ ì ìˆ˜ ê³„ì‚°
        overall = relevance * 0.4 + naturalness * 0.3 + consistency * 0.3
        
        return ValidationMetrics(
            relevance_score=relevance,
            naturalness_score=naturalness,
            context_consistency=consistency,
            overall_score=overall
        )
    
    def _calculate_relevance(self, user_message: str, response: str) -> float:
        """ì§ˆë¬¸-ë‹µë³€ ê´€ë ¨ì„± ê³„ì‚°"""
        score = 50.0  # ê¸°ë³¸ ì ìˆ˜
        
        # ì§ˆë¬¸ íƒ€ì… íŒŒì•…
        question_type = self._identify_question_type(user_message)
        
        # ì§ˆë¬¸ íƒ€ì…ë³„ ê²€ì¦
        if question_type == 'what_doing':
            if any(word in response for word in ['í•˜ê³  ìˆ', 'í•˜ëŠ” ì¤‘', 'í–ˆì–´', 'í•  ê±°']):
                score += 30
            elif 'ê·¸ë˜' in response or 'ë‚˜ë„' in response:
                score -= 20
                
        elif question_type == 'spoiler':
            if 'ì•ˆ ë´¤' in response or 'ë§í•˜ì§€ ë§ˆ' in response:
                score += 40
            elif 'ê´œì°®ì•„' in response or 'ë§í•´' in response:
                score -= 30
                
        elif question_type == 'direct_viewing':
            if 'ì˜í™”' in response or 'ë“œë¼ë§ˆ' in response or 'ì½˜í…ì¸ ' in response:
                score += 30
            elif 'ë§Œë‚˜' in response:
                score -= 40
                
        elif question_type == 'how_feeling':
            if any(word in response for word in ['ìŠ¬í”„', 'ê¸°ì˜', 'í™”ë‚˜', 'ì¢‹']):
                score += 20
                
        # í‚¤ì›Œë“œ ë§¤ì¹­ ë³´ë„ˆìŠ¤
        user_keywords = self._extract_keywords(user_message)
        response_keywords = self._extract_keywords(response)
        common_keywords = set(user_keywords) & set(response_keywords)
        
        if common_keywords:
            score += min(len(common_keywords) * 10, 30)
            
        return min(max(score, 0), 100)
    
    def _calculate_naturalness(self, response: str, user_message: str) -> float:
        """ìì—°ìŠ¤ëŸ¬ì›€ ì ìˆ˜ ê³„ì‚°"""
        score = 70.0  # ê¸°ë³¸ ì ìˆ˜
        
        # ë¬¼ìŒí‘œ ì¼ì¹˜ì„±
        if self._is_question(response) and response.endswith('?'):
            score += 10
        elif self._is_question(response) and not response.endswith('?'):
            score -= 20
            
        # ë¶€ë“œëŸ¬ìš´ í‘œí˜„ ì‚¬ìš©
        if any(expr in response for expr in ['ì–´ìš”?', 'ì„ê¹Œìš”?', 'ê¹Œìš”?']):
            score += 15
        elif any(expr in response for expr in ['ë‚˜ìš”?', 'ìŠµë‹ˆê¹Œ?']):
            score -= 10
            
        # ê³µê° í‘œí˜„
        empathy_patterns = [
            'ì§„ì§œ.*ê² ', 'ì •ë§.*ê² ', 'ì•„.*ìŠ¬í”„', 'ì™€.*ëŒ€ë°•', 
            'í—.*ì§„ì§œ', 'ì•„ì´ê³ .*ì–´ë–¡í•´'
        ]
        if any(re.search(pattern, response) for pattern in empathy_patterns):
            score += 15
        elif 'ê·¸ëŸ° ê°ì • ì´í•´í•´ìš”' in response or 'ê·¸ëŸ° ê¸°ë¶„ ì•Œì•„ìš”' in response:
            score -= 15
            
        # ì•„ì´ìŠ¤ë¸Œë ˆì´í‚¹ (ì²« ì¸ì‚¬)
        if 'ë°˜ê°€ì›Œ' in response or 'ì•ˆë…•' in response:
            if response.endswith('!') and len(response) < 15:
                score -= 10  # ë„ˆë¬´ ì§§ì€ ì¸ì‚¬
            elif '?' in response:
                score += 10  # ì§ˆë¬¸ í¬í•¨
                
        return min(max(score, 0), 100)
    
    def _calculate_consistency(self, response: str, context: List[Dict]) -> float:
        """ë¬¸ë§¥ ì¼ê´€ì„± ì ìˆ˜ ê³„ì‚°"""
        if not context or len(context) < 2:
            return 70.0
            
        score = 80.0
        
        # ì´ì „ ëŒ€í™”ì™€ì˜ í‚¤ì›Œë“œ ì—°ê´€ì„±
        prev_keywords = []
        for msg in context[-3:]:  # ìµœê·¼ 3ê°œ ë©”ì‹œì§€
            prev_keywords.extend(self._extract_keywords(msg.get('content', '')))
            
        response_keywords = self._extract_keywords(response)
        
        if prev_keywords and response_keywords:
            overlap_ratio = len(set(prev_keywords) & set(response_keywords)) / len(set(response_keywords))
            score = 50 + overlap_ratio * 50
            
        return min(max(score, 0), 100)
    
    def _identify_question_type(self, message: str) -> str:
        """ì§ˆë¬¸ íƒ€ì… ì‹ë³„"""
        if 'ë­í•´' in message or 'ë­í•˜ê³ ' in message or 'ë­ í•˜ê³ ' in message:
            return 'what_doing'
        elif 'ìŠ¤í¬' in message and ('ë§í•´ë„' in message or 'í•´ë„' in message):
            return 'spoiler'
        elif 'ì§ì ‘ ë³´' in message or 'ì§ì ‘ ë´' in message:
            return 'direct_viewing'
        elif 'ì–´ë•Œ' in message or 'ê¸°ë¶„' in message:
            return 'how_feeling'
        else:
            return 'general'
    
    def _is_question(self, text: str) -> bool:
        """ì§ˆë¬¸ ì—¬ë¶€ íŒë‹¨"""
        question_endings = ['ë‚˜ìš”', 'ê¹Œìš”', 'ì„ê¹Œ', 'ì–´ìš”', 'ì£ ', 'ë‹ˆ', 'ê°€ìš”']
        question_words = ['ë­', 'ì–´ë””', 'ì–¸ì œ', 'ëˆ„êµ¬', 'ì™œ', 'ì–´ë–»ê²Œ', 'ì–¼ë§ˆë‚˜']
        
        # ë¬¼ìŒí‘œê°€ ìˆìœ¼ë©´ í™•ì‹¤íˆ ì§ˆë¬¸
        if '?' in text:
            return True
            
        # ì˜ë¬¸ì‚¬ê°€ ìˆìœ¼ë©´ ì§ˆë¬¸
        if any(word in text for word in question_words):
            return True
            
        # ì˜ë¬¸í˜• ì–´ë¯¸ë¡œ ëë‚˜ë©´ ì§ˆë¬¸
        for ending in question_endings:
            if text.rstrip('.!').endswith(ending):
                return True
                
        return False
    
    def _extract_keywords(self, text: str) -> List[str]:
        """í‚¤ì›Œë“œ ì¶”ì¶œ"""
        stopwords = ['ì€', 'ëŠ”', 'ì´', 'ê°€', 'ì„', 'ë¥¼', 'ì—', 'ì—ì„œ', 'ìœ¼ë¡œ', 'ì™€', 'ê³¼', 'ë„', 'ë§Œ', 'ì˜']
        words = re.findall(r'\w+', text.lower())
        keywords = [word for word in words if word not in stopwords and len(word) >= 2]
        return keywords
    
    def _generate_reason(self, original: ValidationMetrics, improved: ValidationMetrics, 
                        improvement_rate: float) -> str:
        """ê°œì„  ì´ìœ  ìƒì„±"""
        reasons = []
        
        if improved.relevance_score > original.relevance_score + 10:
            reasons.append("ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ê´€ë ¨ì„± í–¥ìƒ")
        elif improved.relevance_score < original.relevance_score - 10:
            reasons.append("ë‹µë³€ ê´€ë ¨ì„± ì €í•˜")
            
        if improved.naturalness_score > original.naturalness_score + 10:
            reasons.append("ìì—°ìŠ¤ëŸ¬ìš´ í‘œí˜„ìœ¼ë¡œ ê°œì„ ")
        elif improved.naturalness_score < original.naturalness_score - 10:
            reasons.append("ë¶€ìì—°ìŠ¤ëŸ¬ìš´ í‘œí˜„ ì¦ê°€")
            
        if improved.context_consistency > original.context_consistency + 10:
            reasons.append("ë¬¸ë§¥ ì¼ê´€ì„± í–¥ìƒ")
            
        if improvement_rate >= 10:
            reasons.append(f"ì „ì²´ í’ˆì§ˆ {improvement_rate:.1f}% í–¥ìƒ")
        elif improvement_rate <= -10:
            reasons.append(f"ì „ì²´ í’ˆì§ˆ {abs(improvement_rate):.1f}% ì €í•˜")
            
        return " / ".join(reasons) if reasons else "ë¯¸ë¯¸í•œ ë³€í™”"
    
    # ê°œì„  íŒ¨í„´ êµ¬í˜„ ë©”ì„œë“œë“¤
    def _add_question_mark(self, text: str) -> str:
        """ë¬¼ìŒí‘œ ì¶”ê°€"""
        if self._is_question(text) and not text.endswith('?'):
            return text.rstrip('.!') + '?'
        return text
    
    def _soften_expression(self, text: str) -> str:
        """í‘œí˜„ ë¶€ë“œëŸ½ê²Œ"""
        text = re.sub(r'ë‚˜ìš”\?', 'ì–´ìš”?', text)
        text = re.sub(r'ìŠµë‹ˆê¹Œ\?', 'ì–´ìš”?', text)
        text = re.sub(r'ê¹Œìš”\?', 'ì„ê¹Œìš”?', text)
        return text
    
    def _enhance_empathy(self, text: str) -> str:
        """ê³µê° í‘œí˜„ ê°•í™”"""
        empathy_map = {
            'ê·¸ëŸ° ê°ì • ì´í•´í•´ìš”': 'ì•„ ì§„ì§œ ê·¸ë¬ê² ë‹¤ã… ã… ',
            'ê·¸ëŸ° ê¸°ë¶„ ì•Œì•„ìš”': 'í— ì™„ì „ ê³µê°ë¼ìš”',
            'ê·¸ëŸ° ë§ˆìŒ ì´í•´í•´ìš”': 'ì™€ ì €ë„ ê·¸ëŸ° ì  ìˆì–´ìš”'
        }
        for old, new in empathy_map.items():
            text = text.replace(old, new)
        return text
    
    def _ensure_direct_answer(self, user_msg: str, response: str) -> str:
        """ì§ì ‘ì ì¸ ë‹µë³€ ë³´ì¥"""
        if any(word in user_msg for word in ['ë­í•´', 'ë­í•˜ê³ ', 'ë­ í•˜ê³ ']):
            # ì™„ì „íˆ ì—‰ëš±í•œ ë‹µë³€ì¸ ê²½ìš°
            if 'ë‚˜ë„ ê·¸ë˜' in response or 'í— ëŒ€ë°•' in response and not any(word in response for word in ['í•˜ê³ ', 'í•˜ëŠ”', 'í–ˆ']):
                return "ì§€ê¸ˆì€ ë‹¹ì‹ ê³¼ ëŒ€í™”í•˜ê³  ìˆì–´ìš”! ê·¸ì „ì—ëŠ” ì¢€ ì‰¬ê³  ìˆì—ˆì–´ìš”. ë‹¹ì‹ ì€ ë­í•˜ê³  ìˆì—ˆì–´ìš”?"
            # ë‹µë³€ì´ ì¤‘ê°„ì— ëŠê¸´ ê²½ìš°
            elif response.endswith(('ì— ëŒ€í•´', 'í•˜ë©´ì„œ', 'ìˆì—ˆ', 'ì€', 'ëŠ”')):
                return response + " ìˆì—ˆì–´ìš”. ë‹¹ì‹ ì€ ë­í•˜ê³  ê³„ì…¨ì–´ìš”?"
        return response
    
    def _handle_spoiler(self, user_msg: str, response: str) -> str:
        """ìŠ¤í¬ì¼ëŸ¬ ì²˜ë¦¬"""
        if 'ìŠ¤í¬' in user_msg and 'ë§í•´ë„' in user_msg:
            if 'ê´œì°®ì•„' in response or 'ë§í•´' in response:
                return "ì•— ì ê¹! ì•„ì§ ì•ˆ ë´¤ìœ¼ë©´ ë§í•˜ì§€ ë§ˆì„¸ìš”! ë‚˜ì¤‘ì— ë³´ê³  ì–˜ê¸°í•´ìš”!"
        return response
    
    def _understand_context(self, user_msg: str, response: str) -> str:
        """ë¬¸ë§¥ ì´í•´"""
        if 'ì§ì ‘ ë³´' in user_msg or 'ì§ì ‘ ë´' in user_msg:
            if 'ë§Œë‚˜' in response:
                return response.replace('ë§Œë‚˜', 'ê·¸ ì‘í’ˆì„ ì§ì ‘ ë³´')
        return response

def validate_chat_improvements(error_keys: List[str] = None):
    """ëŒ€í™” ê°œì„  ì‚¬í•­ì„ ê²€ì¦í•˜ê³  ì ìš©"""
    validator = ChatImprovementValidator()
    
    # ë¶„ì„ ê²°ê³¼ íŒŒì¼ ì°¾ê¸°
    analysis_dir = os.path.join(os.path.dirname(__file__), "analysis_results")
    
    # ìµœê·¼ 3ê°œì˜ ë¶„ì„ íŒŒì¼ ê°€ì ¸ì˜¤ê¸°
    detail_files = []
    for filename in os.listdir(analysis_dir):
        if filename.startswith("detailed_") and filename.endswith(".json"):
            file_path = os.path.join(analysis_dir, filename)
            detail_files.append((file_path, os.path.getmtime(file_path)))
    
    detail_files.sort(key=lambda x: x[1], reverse=True)
    detail_files = detail_files[:3]  # ìµœê·¼ 3ê°œë§Œ
    
    if not detail_files:
        print("ë¶„ì„ ê²°ê³¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ëª¨ë“  ë¶„ì„ ê²°ê³¼ í•©ì¹˜ê¸°
    all_analysis_results = []
    for file_path, _ in detail_files:
        with open(file_path, 'r', encoding='utf-8') as f:
            results = json.load(f)
            all_analysis_results.extend(results)
    
    print(f"ğŸ“Š ê°œì„  ê²€ì¦ ì‹œì‘: {len(detail_files)}ê°œ íŒŒì¼, {len(all_analysis_results)}ê°œ ë¶„ì„ ê²°ê³¼")
    print("="*80)
    
    # ê²€ì¦ ê²°ê³¼ ì €ì¥
    validation_results = []
    total_improvements = 0
    applied_improvements = 0
    
    for result in all_analysis_results:
        if error_keys and result['error_key'] not in error_keys:
            continue
            
        persona_name = result['persona_name']
        issues = result['issues']
        
        print(f"\nğŸ‘¤ {persona_name} í˜ë¥´ì†Œë‚˜ ê²€ì¦ ì¤‘...")
        
        for issue in issues:
            if issue['severity'] in ['high', 'critical']:
                user_msg = issue['user_message']
                original_response = issue['ai_response']
                
                # ê°œì„  ì ìš©
                improved_response = original_response
                
                # ë¬¼ìŒí‘œ ì¶”ê°€
                improved_response = validator._add_question_mark(improved_response)
                
                # í‘œí˜„ ë¶€ë“œëŸ½ê²Œ
                improved_response = validator._soften_expression(improved_response)
                
                # ê³µê° í‘œí˜„ ê°•í™”
                improved_response = validator._enhance_empathy(improved_response)
                
                # ì§ì ‘ ë‹µë³€ ë³´ì¥
                if 'ë­í•´' in user_msg or 'ë­í•˜ê³ ' in user_msg:
                    improved_response = validator._ensure_direct_answer(user_msg, improved_response)
                
                # ìŠ¤í¬ì¼ëŸ¬ ì²˜ë¦¬
                if 'ìŠ¤í¬' in user_msg:
                    improved_response = validator._handle_spoiler(user_msg, improved_response)
                
                # ë¬¸ë§¥ ì´í•´
                if 'ì§ì ‘' in user_msg:
                    improved_response = validator._understand_context(user_msg, improved_response)
                
                # ê²€ì¦
                validation = validator.validate_improvement(
                    user_message=user_msg,
                    original_response=original_response,
                    improved_response=improved_response
                )
                
                validation_results.append({
                    'persona_name': persona_name,
                    'issue_type': issue['type'],
                    'validation': validation
                })
                
                total_improvements += 1
                if validation.applied:
                    applied_improvements += 1
                    print(f"  âœ… ê°œì„  ì ìš©: {validation.reason}")
                    print(f"     ì›ë³¸: {original_response[:50]}...")
                    print(f"     ê°œì„ : {improved_response[:50]}...")
                    print(f"     ì ìˆ˜: {validation.original_score:.1f} â†’ {validation.improved_score:.1f} (+{validation.improvement_rate:.1f}%)")
                else:
                    print(f"  âŒ ê°œì„  ë¯¸ì ìš©: {validation.reason}")
    
    # ê²°ê³¼ ìš”ì•½
    print("\n" + "="*80)
    print("ğŸ“ˆ ê²€ì¦ ê²°ê³¼ ìš”ì•½")
    print(f"  - ì´ ê°œì„  ì‹œë„: {total_improvements}ê±´")
    if total_improvements > 0:
        print(f"  - ì ìš©ëœ ê°œì„ : {applied_improvements}ê±´ ({applied_improvements/total_improvements*100:.1f}%)")
    else:
        print(f"  - ì ìš©ëœ ê°œì„ : 0ê±´ (ê°œì„  ëŒ€ìƒ ì—†ìŒ)")
    
    # í˜ë¥´ì†Œë‚˜ë³„ í†µê³„
    persona_stats = defaultdict(lambda: {'total': 0, 'applied': 0})
    for result in validation_results:
        stats = persona_stats[result['persona_name']]
        stats['total'] += 1
        if result['validation'].applied:
            stats['applied'] += 1
    
    print("\ní˜ë¥´ì†Œë‚˜ë³„ ê°œì„  ì ìš©ë¥ :")
    for persona, stats in persona_stats.items():
        apply_rate = stats['applied'] / stats['total'] * 100 if stats['total'] > 0 else 0
        print(f"  - {persona}: {stats['applied']}/{stats['total']} ({apply_rate:.1f}%)")
    
    # ê²°ê³¼ ì €ì¥
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_path = os.path.join(analysis_dir, f"validation_{timestamp}.json")
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump({
            'timestamp': timestamp,
            'total_improvements': total_improvements,
            'applied_improvements': applied_improvements,
            'apply_rate': applied_improvements/total_improvements*100 if total_improvements > 0 else 0,
            'persona_stats': dict(persona_stats),
            'detailed_results': [
                {
                    'persona_name': r['persona_name'],
                    'issue_type': r['issue_type'],
                    'user_message': r['validation'].user_message,
                    'original_response': r['validation'].original_response,
                    'improved_response': r['validation'].improved_response,
                    'original_score': r['validation'].original_score,
                    'improved_score': r['validation'].improved_score,
                    'improvement_rate': r['validation'].improvement_rate,
                    'applied': r['validation'].applied,
                    'reason': r['validation'].reason
                }
                for r in validation_results
            ]
        }, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ ê²€ì¦ ê²°ê³¼ ì €ì¥: {output_path}")
    
    return validation_results

if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser(description='ëŒ€í™” ê°œì„  ê²€ì¦ ë„êµ¬')
    parser.add_argument('--error-keys', nargs='+', help='íŠ¹ì • ì—ëŸ¬ í‚¤ë§Œ ê²€ì¦')
    args = parser.parse_args()
    
    validate_chat_improvements(error_keys=args.error_keys)