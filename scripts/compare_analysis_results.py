import json
import os
from datetime import datetime
import glob
import sys
import io

# UTF-8 ì¸ì½”ë”© ì„¤ì •
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')

def load_latest_analysis():
    """ê°€ì¥ ìµœê·¼ ë¶„ì„ ê²°ê³¼ ë¡œë“œ"""
    analysis_dir = 'analysis_results'
    
    # ëª¨ë“  summary íŒŒì¼ ì°¾ê¸°
    summary_files = glob.glob(os.path.join(analysis_dir, 'summary_*.json'))
    
    if not summary_files:
        print("ë¶„ì„ ê²°ê³¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    # ê°€ì¥ ìµœê·¼ íŒŒì¼ ì°¾ê¸°
    latest_file = max(summary_files, key=os.path.getctime)
    
    with open(latest_file, 'r', encoding='utf-8') as f:
        return json.load(f), latest_file

def compare_results(before, after):
    """ê°œì„  ì „í›„ ê²°ê³¼ ë¹„êµ"""
    print("\n" + "="*60)
    print("ëŒ€í™” í’ˆì§ˆ ê°œì„  ì „í›„ ë¹„êµ ë¶„ì„")
    print("="*60)
    
    # ì „ì²´ ì ìˆ˜ ë¹„êµ
    print("\nğŸ“Š ì „ì²´ ì ìˆ˜ ë¹„êµ:")
    print("-" * 40)
    
    metrics = [
        ('í‰ê·  ì¼ê´€ì„±', 'average_coherence', 80),
        ('í‰ê·  ì£¼ì œ ì¼ê´€ì„±', 'average_topic_consistency', 60),
        ('í‰ê·  ìì—°ìŠ¤ëŸ¬ì›€', 'average_naturalness', 75)
    ]
    
    for name, key, target in metrics:
        before_val = before.get(key, 0)
        after_val = after.get(key, 0)
        improvement = after_val - before_val
        
        status = "âœ…" if after_val >= target else "âš ï¸"
        trend = "â†‘" if improvement > 0 else ("â†“" if improvement < 0 else "â†’")
        
        print(f"{status} {name}:")
        print(f"   ê°œì„  ì „: {before_val:.1f}/100")
        print(f"   ê°œì„  í›„: {after_val:.1f}/100 {trend}")
        print(f"   ë³€í™”ëŸ‰: {improvement:+.1f} (ëª©í‘œ: {target}+)")
    
    # ë¬¸ì œ íŒ¨í„´ ë¹„êµ
    print("\nğŸ” ë¬¸ì œ íŒ¨í„´ ë°œìƒ ê±´ìˆ˜:")
    print("-" * 40)
    
    patterns = [
        ('ê´€ë ¨ ì—†ëŠ” ë‹µë³€', 'irrelevant_answer', 5),
        ('ì£¼ì œ ê¸‰ë³€', 'abrupt_topic_change', 5),
        ('ì¸ì‚¬ë§ ë°˜ë³µ', 'greeting_repetition', 0),
        ('ë§¤í¬ë¡œ ì‘ë‹µ', 'macro_response', 0),
        ('íšŒí”¼ íŒ¨í„´', 'avoidance_pattern', 2),
        ('ê°ì • ë¶ˆì¼ì¹˜', 'emotion_inconsistency', 2)
    ]
    
    before_patterns = before.get('pattern_counts', {})
    after_patterns = after.get('pattern_counts', {})
    
    for name, key, target in patterns:
        before_count = before_patterns.get(key, 0)
        after_count = after_patterns.get(key, 0)
        reduction = before_count - after_count
        
        status = "âœ…" if after_count <= target else "âš ï¸"
        trend = "â†“" if reduction > 0 else ("â†‘" if reduction < 0 else "â†’")
        
        print(f"{status} {name}:")
        print(f"   ê°œì„  ì „: {before_count}ê±´")
        print(f"   ê°œì„  í›„: {after_count}ê±´ {trend}")
        print(f"   ê°ì†ŒëŸ‰: {reduction:+d} (ëª©í‘œ: {target}ê±´ ì´í•˜)")
    
    # ì‹¬ê°ë„ë³„ ë¶„í¬
    print("\nâš ï¸ ì‹¬ê°ë„ë³„ ë¬¸ì œ ë¶„í¬:")
    print("-" * 40)
    
    severities = ['CRITICAL', 'HIGH', 'MEDIUM', 'LOW']
    
    before_severity = before.get('severity_distribution', {})
    after_severity = after.get('severity_distribution', {})
    
    for severity in severities:
        before_count = before_severity.get(severity, 0)
        after_count = after_severity.get(severity, 0)
        reduction = before_count - after_count
        
        trend = "â†“" if reduction > 0 else ("â†‘" if reduction < 0 else "â†’")
        
        print(f"{severity}:")
        print(f"   ê°œì„  ì „: {before_count}ê±´")
        print(f"   ê°œì„  í›„: {after_count}ê±´ {trend}")
    
    # ê°œì„ ìœ¨ ê³„ì‚°
    print("\nğŸ“ˆ ê°œì„  ì„±ê³¼ ìš”ì•½:")
    print("-" * 40)
    
    # ì ìˆ˜ ê°œì„ ìœ¨
    score_improvements = []
    for name, key, _ in metrics:
        before_val = before.get(key, 0)
        after_val = after.get(key, 0)
        if before_val > 0:
            improvement_rate = ((after_val - before_val) / before_val) * 100
            score_improvements.append(improvement_rate)
    
    avg_score_improvement = sum(score_improvements) / len(score_improvements) if score_improvements else 0
    
    # ë¬¸ì œ ê°ì†Œìœ¨
    total_before_issues = sum(before_patterns.values())
    total_after_issues = sum(after_patterns.values())
    issue_reduction_rate = ((total_before_issues - total_after_issues) / total_before_issues * 100) if total_before_issues > 0 else 0
    
    print(f"â€¢ í‰ê·  ì ìˆ˜ ê°œì„ ìœ¨: {avg_score_improvement:+.1f}%")
    print(f"â€¢ ì „ì²´ ë¬¸ì œ ê°ì†Œìœ¨: {issue_reduction_rate:.1f}%")
    print(f"â€¢ ì´ ë¬¸ì œ ê±´ìˆ˜: {total_before_issues}ê±´ â†’ {total_after_issues}ê±´")
    
    # ëª©í‘œ ë‹¬ì„± ì—¬ë¶€
    print("\nğŸ¯ ëª©í‘œ ë‹¬ì„± í˜„í™©:")
    print("-" * 40)
    
    goals_achieved = 0
    total_goals = len(metrics) + len(patterns)
    
    for _, key, target in metrics:
        if after.get(key, 0) >= target:
            goals_achieved += 1
    
    for _, key, target in patterns:
        if after_patterns.get(key, 0) <= target:
            goals_achieved += 1
    
    achievement_rate = (goals_achieved / total_goals) * 100
    
    print(f"ë‹¬ì„±ëœ ëª©í‘œ: {goals_achieved}/{total_goals} ({achievement_rate:.1f}%)")
    
    if achievement_rate >= 80:
        print("âœ… ê°œì„  ëª©í‘œë¥¼ ì„±ê³µì ìœ¼ë¡œ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤!")
    elif achievement_rate >= 60:
        print("âš ï¸ ë¶€ë¶„ì ìœ¼ë¡œ ê°œì„ ë˜ì—ˆìœ¼ë‚˜ ì¶”ê°€ ì‘ì—…ì´ í•„ìš”í•©ë‹ˆë‹¤.")
    else:
        print("âŒ ê°œì„  íš¨ê³¼ê°€ ë¯¸í¡í•©ë‹ˆë‹¤. ì¶”ê°€ ë¶„ì„ì´ í•„ìš”í•©ë‹ˆë‹¤.")
    
    return {
        'avg_score_improvement': avg_score_improvement,
        'issue_reduction_rate': issue_reduction_rate,
        'achievement_rate': achievement_rate
    }

def main():
    # ê°œì„  ì „ ê²°ê³¼ (í•˜ë“œì½”ë”© - ì´ì „ í…ŒìŠ¤íŠ¸ ê²°ê³¼)
    before_results = {
        'average_coherence': 58.5,
        'average_topic_consistency': 22.0,
        'average_naturalness': 56.7,
        'pattern_counts': {
            'irrelevant_answer': 24,
            'abrupt_topic_change': 16,
            'greeting_repetition': 3,
            'macro_response': 1,
            'avoidance_pattern': 7,
            'emotion_inconsistency': 4
        },
        'severity_distribution': {
            'CRITICAL': 1,
            'HIGH': 8,
            'MEDIUM': 7,
            'LOW': 4
        }
    }
    
    # ê°œì„  í›„ ê²°ê³¼ ë¡œë“œ
    result = load_latest_analysis()
    
    if result:
        after_results, filename = result
        print(f"\nìµœì‹  ë¶„ì„ íŒŒì¼: {filename}")
        
        # ë¹„êµ ë¶„ì„ ì‹¤í–‰
        comparison = compare_results(before_results, after_results)
        
        # ê²°ê³¼ ì €ì¥
        output_file = f'analysis_results/comparison_{datetime.now().strftime("%Y%m%d_%H%M%S")}.json'
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump({
                'before': before_results,
                'after': after_results,
                'comparison': comparison,
                'timestamp': datetime.now().isoformat()
            }, f, ensure_ascii=False, indent=2)
        
        print(f"\në¹„êµ ê²°ê³¼ê°€ {output_file}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    else:
        print("\nê°œì„  í›„ í…ŒìŠ¤íŠ¸ë¥¼ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”:")
        print("python scripts/analyze_chat_errors.py --recheck")

if __name__ == "__main__":
    main()