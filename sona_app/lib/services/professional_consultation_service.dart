import 'dart:async';
import 'dart:convert';
import 'package:flutter/material.dart';
import 'package:http/http.dart' as http;
import 'package:flutter_dotenv/flutter_dotenv.dart';
import '../models/message.dart';
import '../models/persona.dart';
import 'enhanced_specialist_service.dart';
import 'quality_logging_service.dart';

/// ğŸ©º Professional Consultation Service for Expert Personas
/// 
/// This service ensures premium quality for paid consultations by:
/// 1. Using optimized AI models for all persona interactions
/// 2. Implementing multi-layer quality validation
/// 3. Crisis detection and appropriate referrals
/// 4. Professional boundaries enforcement
/// 5. Real-time quality monitoring
class ProfessionalConsultationService {
  static const String _baseUrl = 'https://api.openai.com/v1/chat/completions';
  static String get _apiKey => dotenv.env['OPENAI_API_KEY'] ?? '';
  
  // Single model for all consultation types
  static const String _model = 'gpt-3.5-turbo'; // Using GPT-3.5-turbo for all consultations
  
  // Quality-focused parameters
  static const int _maxInputTokens = 4000; // More context for better responses
  static const int _maxOutputTokens = 800; // Longer, more detailed responses
  static const double _temperature = 0.3; // Lower for more consistent, professional tone
  
  static final http.Client _httpClient = http.Client();
  
  /// Generate professional consultation response
  static Future<ConsultationResult> generateProfessionalResponse({
    required Persona persona,
    required List<Message> chatHistory,
    required String userMessage,
    required bool isPaidConsultation,
    String? userId,
  }) async {
    try {
      // 1. Crisis detection first
      final crisisCheck = EnhancedSpecialistService.detectCrisisSignals(userMessage);
      if (crisisCheck['isCrisis'] == true) {
        // Log crisis detection
        if (userId != null) {
          await QualityLoggingService.logCrisisDetection(
            userId: userId,
            persona: persona,
            userMessage: userMessage,
            crisisType: crisisCheck['urgency'] ?? 'high',
            responseGiven: crisisCheck['response'],
          );
        }
        
        return ConsultationResult(
          response: crisisCheck['response'],
          qualityScore: 1.0,
          isCrisisResponse: true,
          requiresHumanReview: true,
        );
      }
      
      // 2. Generate enhanced prompt for specialists
      final conversationContext = _buildConversationContext(chatHistory);
      final enhancedPrompt = EnhancedSpecialistService.generateEnhancedPrompt(
        persona, 
        conversationContext
      );
      
      // 3. Choose appropriate model based on consultation type
      final model = _getModelForPersona(persona, isPaidConsultation);
      
      // 4. Make API call with quality parameters
      final response = await _makeQualityApiCall(
        prompt: enhancedPrompt,
        userMessage: userMessage,
        chatHistory: chatHistory,
        model: model,
      );
      
      // 5. Validate response quality
      final qualityValidation = _validateProfessionalResponse(response, persona);
      
      // 6. If quality is insufficient, retry with stricter prompt
      if (qualityValidation['score'] < 0.7 && isPaidConsultation) {
        debugPrint('âš ï¸ Low quality response detected, retrying with enhanced prompt');
        final retryResponse = await _retryWithStricterPrompt(
          enhancedPrompt, userMessage, chatHistory, model
        );
        
        return ConsultationResult(
          response: retryResponse,
          qualityScore: 0.8, // Assume better quality after retry
          isCrisisResponse: false,
          requiresHumanReview: false,
        );
      }
      
      // 7. Log metrics for monitoring
      final metrics = ConsultationMetrics.analyzeSession(
        userMessage, response, persona.isExpert ? 'specialist' : 'normal'
      );
      
      // Log quality metrics to Firebase for dashboard monitoring
      if (userId != null) {
        await QualityLoggingService.logConsultationQuality(
          userId: userId,
          persona: persona,
          userMessage: userMessage,
          aiResponse: response,
          qualityMetrics: metrics,
          isCrisisResponse: false,
          requiresHumanReview: qualityValidation['score'] < 0.5,
        );
        
        // Update persona and daily stats
        await Future.wait([
          QualityLoggingService.updatePersonaQualityStats(
            personaId: persona.id,
            personaType: persona.isExpert ? 'specialist' : 'normal',
            qualityScore: qualityValidation['score'],
            isCrisisResponse: false,
          ),
          QualityLoggingService.updateDailyQualityStats(
            qualityScore: qualityValidation['score'],
            personaType: persona.isExpert ? 'specialist' : 'normal',
            isCrisisResponse: false,
          ),
        ]);
      }
      
      return ConsultationResult(
        response: response,
        qualityScore: qualityValidation['score'],
        isCrisisResponse: false,
        requiresHumanReview: qualityValidation['score'] < 0.5,
        metrics: metrics,
      );
      
    } catch (e) {
      debugPrint('âŒ Professional consultation error: $e');
      return ConsultationResult(
        response: _getEmergencyFallbackResponse(persona),
        qualityScore: 0.3,
        isCrisisResponse: false,
        requiresHumanReview: true,
        error: e.toString(),
      );
    }
  }
  
  /// Determine appropriate model based on persona and payment status
  static String _getModelForPersona(Persona persona, bool isPaidConsultation) {
    // All consultations now use the same model for consistent quality
    return _model;
  }
  
  /// Make quality-focused API call
  static Future<String> _makeQualityApiCall({
    required String prompt,
    required String userMessage,
    required List<Message> chatHistory,
    required String model,
  }) async {
    final messages = _buildMessageHistory(prompt, chatHistory, userMessage);
    
    final body = json.encode({
      'model': model,
      'messages': messages,
      'max_tokens': _maxOutputTokens,
      'temperature': _temperature,
      'top_p': 0.9, // Slightly focused for consistency
      'frequency_penalty': 0.3, // Reduce repetition
      'presence_penalty': 0.1, // Encourage new topics
    });
    
    final response = await _httpClient.post(
      Uri.parse(_baseUrl),
      headers: {
        'Content-Type': 'application/json',
        'Authorization': 'Bearer $_apiKey',
      },
      body: body,
    );
    
    if (response.statusCode == 200) {
      final data = json.decode(response.body);
      return data['choices'][0]['message']['content'].toString().trim();
    } else {
      throw Exception('API call failed: ${response.statusCode} ${response.body}');
    }
  }
  
  /// Retry with stricter quality requirements
  static Future<String> _retryWithStricterPrompt(
    String basePrompt, 
    String userMessage, 
    List<Message> chatHistory, 
    String model
  ) async {
    final strictPrompt = '''
$basePrompt

ğŸ’¡ í’ˆì§ˆ ë³´ì¥ ìš”êµ¬ì‚¬í•­:
- ë”°ëœ»í•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ ìƒë‹´ í†¤ ìœ ì§€
- ìƒë‹´ìì˜ ìƒí™©ì„ ì¶©ë¶„íˆ ì´í•´í•˜ê³  ê³µê°
- ì „ë¬¸ì  ì¡°ì–¸ì„ ì¼ìƒ ì–¸ì–´ë¡œ ì‰½ê²Œ ì„¤ëª…
- êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ì¡°ì–¸ì„ ëŒ€í™” ì†ì— ìì—°ìŠ¤ëŸ½ê²Œ ì œê³µ
- í”¼ìƒì  í‘œí˜„ ëŒ€ì‹  ì§„ì •ì„± ìˆëŠ” ê²©ë ¤ì™€ ì§€ì§€

ì´ê²ƒì€ ì „ë¬¸ ìƒë‹´ì…ë‹ˆë‹¤. ìƒë‹´ìì—ê²Œ ì‹¤ì§ˆì ì¸ ë„ì›€ì„ ì œê³µí•´ì£¼ì„¸ìš”.
''';
    
    return await _makeQualityApiCall(
      prompt: strictPrompt,
      userMessage: userMessage,
      chatHistory: chatHistory,
      model: model,
    );
  }
  
  /// Validate professional response quality
  static Map<String, dynamic> _validateProfessionalResponse(String response, Persona persona) {
    final issues = <String>[];
    double score = 1.0;
    
    // Length check
    if (response.length < 200) {
      issues.add('ì‘ë‹µì´ ë„ˆë¬´ ì§§ìŒ (${response.length}ì)');
      score -= 0.3;
    }
    
    // Superficial phrase detection - ë‹¨ìˆœíˆ ìœ„ë¡œë§Œ í•˜ëŠ” í‘œí˜„
    final superficialPhrases = ['ê·¸ëƒ¥ í˜ë‚´ì„¸ìš”', 'ê·¸ëƒ¥ ê´œì°®ì•„ìš”', 'ë¶„ëª…íˆ ì˜ ë  ê±°ì˜ˆìš”', 'ë„ˆë¬´ ê±±ì •ë§ˆì„¸ìš”'];
    for (final phrase in superficialPhrases) {
      if (response.contains(phrase)) {
        issues.add('í”¼ìƒì  í‘œí˜„ ì‚¬ìš©: $phrase');
        score -= 0.2;
      }
    }
    
    // Professional element check
    final professionalElements = ['ë‹¨ê³„', 'ë°©ë²•', 'ì „ëµ', 'ê¶Œì¥', 'ì œì•ˆ', 'ë¶„ì„'];
    final hasElements = professionalElements.any((element) => response.contains(element));
    if (!hasElements) {
      issues.add('ì „ë¬¸ì  ì¡°ì–¸ êµ¬ì¡° ë¶€ì¡±');
      score -= 0.2;
    }
    
    // Specificity check
    final specificWords = ['êµ¬ì²´ì ìœ¼ë¡œ', 'ì˜ˆë¥¼ ë“¤ì–´', 'ì²«ì§¸', 'ë‘˜ì§¸', 'ì…‹ì§¸'];
    final hasSpecificity = specificWords.any((word) => response.contains(word));
    if (!hasSpecificity) {
      issues.add('êµ¬ì²´ì„± ë¶€ì¡±');
      score -= 0.1;
    }
    
    return {
      'score': score > 0 ? score : 0,
      'issues': issues,
      'passed': score >= 0.7,
    };
  }
  
  /// Build conversation context for better responses
  static String _buildConversationContext(List<Message> chatHistory) {
    if (chatHistory.isEmpty) return '';
    
    final recentMessages = chatHistory.takeLast(6).toList();
    final context = recentMessages.map((msg) => 
      '${msg.isFromUser ? "ì‚¬ìš©ì" : "ìƒë‹´ì‚¬"}: ${msg.content}'
    ).join('\n');
    
    return context;
  }
  
  /// Build message history for API
  static List<Map<String, String>> _buildMessageHistory(
    String systemPrompt,
    List<Message> chatHistory,
    String userMessage,
  ) {
    final messages = <Map<String, String>>[];
    
    // System prompt
    messages.add({
      'role': 'system',
      'content': systemPrompt,
    });
    
    // Recent chat history (last 8 messages for context)
    final recentHistory = chatHistory.takeLast(8).toList();
    for (final message in recentHistory) {
      messages.add({
        'role': message.isFromUser ? 'user' : 'assistant',
        'content': message.content,
      });
    }
    
    // Current user message
    messages.add({
      'role': 'user',
      'content': userMessage,
    });
    
    return messages;
  }
  
  /// Get emergency fallback response
  static String _getEmergencyFallbackResponse(Persona persona) {
    return '''
ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ ê¸°ìˆ ì  ë¬¸ì œë¡œ ì¸í•´ ì¼ì‹œì ìœ¼ë¡œ ìƒë‹´ ì„œë¹„ìŠ¤ì— ì§€ì¥ì´ ìˆìŠµë‹ˆë‹¤.

ê¸´ê¸‰í•œ ìƒë‹´ì´ í•„ìš”í•˜ì‹œë‹¤ë©´:
- ì •ì‹ ê±´ê°•ìƒë‹´ì „í™”: 1577-0199
- ìì‚´ì˜ˆë°©ìƒë‹´ì „í™”: 1393
- ì²­ì†Œë…„ìƒë‹´ì „í™”: 1388

ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì‹œê±°ë‚˜, ê³ ê°ì„¼í„°(support@sona-app.com)ë¡œ ë¬¸ì˜í•´ì£¼ì„¸ìš”.

ë¶ˆí¸ì„ ë“œë ¤ ì£„ì†¡í•©ë‹ˆë‹¤.
''';
  }
  
  /// Log consultation metrics for monitoring
  static void _logConsultationMetrics(Map<String, dynamic> metrics, Persona persona) {
    // TODO: Firebase Analyticsë‚˜ ë³„ë„ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œìœ¼ë¡œ ì „ì†¡
    debugPrint('ğŸ“Š Consultation Metrics: ${persona.name}');
    debugPrint('   Quality Score: ${metrics['response_quality_score']}');
    debugPrint('   Specificity: ${metrics['specificity_score']}');
    debugPrint('   Professional Tone: ${metrics['professional_tone_score']}');
    debugPrint('   Actionability: ${metrics['actionability_score']}');
  }
}

/// Result object for professional consultations
class ConsultationResult {
  final String response;
  final double qualityScore;
  final bool isCrisisResponse;
  final bool requiresHumanReview;
  final Map<String, dynamic>? metrics;
  final String? error;
  
  const ConsultationResult({
    required this.response,
    required this.qualityScore,
    required this.isCrisisResponse,
    required this.requiresHumanReview,
    this.metrics,
    this.error,
  });
  
  bool get isHighQuality => qualityScore >= 0.8;
  bool get isAcceptableQuality => qualityScore >= 0.6;
  bool get needsImprovement => qualityScore < 0.6;
}

/// Extension for list utilities
extension ListUtils<T> on List<T> {
  List<T> takeLast(int count) {
    if (count >= length) return this;
    return sublist(length - count);
  }
}